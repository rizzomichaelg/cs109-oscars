<!DOCTYPE html>
<html class="no-js">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>And the Oscar goes to...</title>
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width">

        <link rel="stylesheet" href="css/bootstrap.min.css">
        <style>
            body {
                padding-top: 50px;
                padding-bottom: 20px;
            }
        </style>
        <link rel="stylesheet" href="css/bootstrap-theme.min.css">
        <link rel="stylesheet" href="css/bootstrap.min.css">
        <link rel="stylesheet" href="css/styles.css">
        <link href="img/favicon.ico" rel="shortcut icon">

        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js"></script>
        <script src="js/jquery-1.10.1.min.js"></script>
        <script src="js/bootstrap.min.js"></script>
        <script src="js/scripts.js"></script>

        <!--[if lt IE 9]>
            <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
            <script>window.html5 || document.write('<script src="js/vendor/html5shiv.js"><\/script>')</script>
        <![endif]-->
    </head>
    <body>
    <div class='wrapper'>

    <div class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class='navbar-brand' href="index.html">Home</a>
        </div>
        <div class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
            <li><a href="getdata.html">Getting the Data</a></li>
            <li><a href="visdata.html">Visualizing the Data</a></li>
            <li><a href="stat.html">Statistical Analysis</a></li>
            <li><a href="predict.html">Predictions</a></li>
            <li><a href="closing_remarks.html">Closing Remarks</a></li>

          </ul>
        </div><!--/.navbar-collapse -->
      </div>
    </div>

    <!-- Main jumbotron for a primary marketing message or call to action -->
    <div class="header">
      <div class="container">
        <h2>Visualizing the Data</h2>
      </div>
    </div>

    <div class="container">
        <b>Box Office Mojo</b>
        <div>
            <p>In order to see a rough distribution of movie studios and Oscar wins/nominations, we visualized frequency of awards or nominations for each studio:</p>
            <img class="vis" src="img/data/bomj_studiocount_all.png">
            <img class="vis" src="img/data/bomj_studiocount_win.png">
            <img class="vis" src="img/data/bomj_studiocount_nom.png">
            <p>An exploration of the studios producing Oscar-candidate movies reveals that some of the largest studios, particularly Buena Vista and Warner Brothers, are the most common studios amongst Oscar nominees and winners. As expected, studios which most frequently produce Oscar nominees are also among the studios that most frequently produce Oscar Winners. (Note: The above analysis is over all movie-based Oscars, as defined previously.)</p>
            <p>Next wanting to investigate further how success in the Oscars goes with different quantitative movie data, we visualized the frequencies of wins and nominations and either the number of theaters or the gross revenue.</p>
            <img class="vis" src="img/data/bomj_ntheaters_all.png">
            <img class="vis" src="img/data/bomj_ntheaters_win.png">
            <img class="vis" src="img/data/bomj_ntheaters_nom.png">
            <img class="vis" src="img/data/bomj_gross_all.png">
            <img class="vis" src="img/data/bomj_gross_win.png">
            <img class="vis" src="img/data/bomj_gross_nom.png">
            <p>As one might reasonably expect, Oscar winners and nominees are more likely to appear in more theaters during their first weekend and draw a larger gross revenue than their less successful counterparts. This result is shown the relative right skew in the nominee and winner histograms.</p>
        </div>
        <hr>
        <b>Review Data</b>
        <div>
            <p>We chose to display the IMDB data here as it is roughly representative of the other review sources.  For information about the other review sources, please see our <a href="http://nbviewer.ipython.org/github/rizzomichaelg/cs109-oscars/blob/master/process_book.ipynb" target="_blank">process book</a>.</p>
            <p>We began by investigating the basic structure for the IMDB DataFrame:
<pre class="text">
Number of reviews: 435,277
Number of critics: 199,188
Number of Movies: 1900
</pre>
            </p>
            <p>We next decided to look at the average number of reviews per user to try to get an idea of the roughly the users' 'rating experience'</p>
            <img class="vis" src="img/data/imdb_revpercrit.png">
            <p>As one can see, although we have a very large number of reviews and reviews, most of them do not interview that many movies themselves.</p>
            <p>Next, we will visualize how the number of reviews changes over the years, and how the average ratings equivalently change.</p>
            <img class="vis" src="img/data/imdb_reviews_over_years.png">
            <p>Interestingly, the peak of user reviews is in 2005, with the number of reviews exponentially falling off until 2011. Thus, it seems that as IMDB became more widespread and popular, <i>fewer</i> people actually have been leaving reviews for movies.</p>
            <p>Now that we have an idea of the distribution of the data over the years, let's look at the actual review ratings. On IMDB users have the option of rating movies without actually leaving a review. Here, we compare the overall movie rating to the average rating user critics give as an approximate measure of whether user critics or general users rate movies more harshly.</p>
<pre class="text">
average movie rating: 6.27 / 10
average user critic rating: 6.27 / 10
</pre>
            <p>From this measure, it appears that the user critics rate the movies the same as the average user. Let's try to visualize this a little more explicitly.</p>
            <img class="vis" src="img/data/imdb_avg_rating.png">
            <p>From this histogram, it appears we have an almost bi-modal distribution where the highest frequency averages are at the polar ends. Considering that a user would be more likely to write a review for a movie if he or she absolutely hated or loved it, this isn't that surprising because then they too would rate it at the extremes.</p>
        </div>
        <div><a class="btn btn-default slide btn-success" href="stat.html">Give me some stats! &raquo;</a></div>
      <hr>
      <footer>
        <p>Presented By: Nick Perkons, Mike Rizzo, Julia Careaga, &amp; Ibrahim Khan</p>
      </footer>
    </div> <!-- /container -->
</div> <!-- wrapper -->
</body>

</html>